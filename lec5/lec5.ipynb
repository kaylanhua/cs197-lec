{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/kaylahuang/Documents/cs197/lec5/lec5.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kaylahuang/Documents/cs197/lec5/lec5.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kaylahuang/Documents/cs197/lec5/lec5.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m CIFAR10\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kaylahuang/Documents/cs197/lec5/lec5.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "\n",
    "# how to set os environment variables\n",
    "# export PATH_DATASETS=\"\" in terminal\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(\n",
    "        (32, 32), scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([],[]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([],[]),\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(\n",
    "    root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
    "# validation set\n",
    "val_dataset = CIFAR10(\n",
    "    root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
    "test_set = CIFAR10(\n",
    "    root=DATASET_PATH, train=False, transform=test_transform, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "# seeding a deep learning model is not trivial\n",
    "# makes sure you are setting pseudorandom numbers in pytorch, numpy, python, etc.\n",
    "# sometimes people forget to set the seed in an individual library and that means they can't reproduce their results easily.\n",
    "\n",
    "# the random split of 45k which we want\n",
    "pl.seed_everything(42)\n",
    "train_set, _ = data.random_split(train_dataset, [45000, 5000])\n",
    "pl.seed_everything(42)\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "# Visualize some examples\n",
    "NUM_IMAGES = 4\n",
    "CIFAR_images = torch.stack(\n",
    "    [val_set[idx][0] for idx in range(NUM_IMAGES)], dim=0)\n",
    "img_grid = torchvision.utils.make_grid(\n",
    "    CIFAR_images, nrow=4, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permut(1,2,0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Image examples of the CIFAR10 dataset\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(\n",
    "    train_set, batch_size=128, \n",
    "    shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = data.DataLoader(\n",
    "    val_set, batch_size=128,\n",
    "    shuffle=False, drop_last=False, num_workers=4)\n",
    "test_loader = data.DataLoader(\n",
    "    test_set, batch_size=128,\n",
    "    shuffle=False, drop_last=False, num_workers=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_patch(x, patch_size, flatten_channels=True):\n",
    "    \"\"\"\n",
    "    Converts an image to patches\n",
    "    Args:\n",
    "        x: tensor representing image of shape (B, C, H, W)\n",
    "        patch_size: number of pixels per dimension of the patches (int)\n",
    "        flatten_channels: whether to flatten the channels \n",
    "        as a feature vector instead of an image grid or not\n",
    "    Returns:\n",
    "        patches: patches of shape (B, C, patch_size, patch_size)\n",
    "    \"\"\"\n",
    "    B, C, H, W = x.shape\n",
    "    \n",
    "    x = x.reshape(\n",
    "        B, # batch\n",
    "        C, # channel \n",
    "        torch.div(H, patch_size, rounding_mode='trunc'),\n",
    "        patch_size,\n",
    "        torch.div(W, patch_size, rounding_mode='floor'),\n",
    "        patch_size,\n",
    "    )\n",
    "    \n",
    "    x = x.permute(0, 2, 4, 1, 3, 5) # [B, H', W', C, p_H, p_W]\n",
    "    x = x.flatten(1, 2) # [B, H'*W', C, p_H, p_W]\n",
    "    \n",
    "    if flatten_channels:\n",
    "        x = x.flatten(2, 4) # [B, H'*W', C*p_H*p_W]\n",
    "        \n",
    "    return x\n",
    "\n",
    "img_patches = img_to_patch(\n",
    "    CIFAR_images, patch_size=4, flatten_channels=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('lec4-2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c813efd9945db1fc5d93a4bceeda3565c4be3cc4bee7939623d06951b49e404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
